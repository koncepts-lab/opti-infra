README.md

# Opti Infrastructure Terraform Azure Deployment

## Overview

This repository contains the Terraform configuration for deploying a robust, secure, and scalable infrastructure on Microsoft Azure. The infrastructure is designed to provide high availability, strong security, and flexible scalability across multiple environments. This deployment represents a migration from AWS to Azure, with architectural adjustments to leverage Azure-native capabilities.

## Migration Changes

### Key Infrastructure Changes

1. **DNS to IP Address Migration**
   - Moved from AWS DNS-based addressing to Azure IP-based addressing
   - Jumpbox now uses public IP instead of public DNS
   - App server uses private IP instead of private DNS
   - Justification: Better alignment with Azure's networking model and simplified DNS management

2. **Authentication Updates**
   - Replaced AWS profile-based authentication with Azure subscription and tenant ID
   - Added explicit admin username variables
   - Enhanced SSH key management with separate keys for jumpbox and app server
   - Justification: Compliance with Azure's security model and more granular access control

3. **Resource Configuration**
   - Added detailed VM size specifications
   - Introduced OS disk configuration options
   - Enhanced redundancy validation (1-3 zones)
   - Justification: Leverage Azure's flexible VM sizing and storage options

### Infrastructure Architecture

### Network Design

- **Availability Zones**: Distributed across 3 Availability Zones
- **Subnet Configuration**: 
  - 6 active subnets (2 per Availability Zone)
    - Virtual Machine subnets
    - NAT Gateway subnets
  - 2 reserved subnets for future expansion

### Key Components

1. **Compute Resources**
   - Single `app_server` deployed in Availability Zone 1
   - Private IP configuration
   - Jumpbox with configurable size (default: Standard_B1s)
   - Customizable OS disk size and type

2. **Network Security**
   - 3 NAT Gateways for high availability
   - Application Gateway with SSL termination
   - Comprehensive Network Security Groups (NSGs)

3. **Storage Infrastructure**
   - Three dedicated storage accounts:
     - `app_data`: Primary application storage
     - `backup_data`: Backup retention
     - `logs`: Load balancer and application logging

4. **Security Measures**
   - Azure Key Vault for certificate and secret management
   - Private network architecture
   - Enhanced key-based Jumpbox access with separate key pairs

## Prerequisites

### System Requirements
- Terraform >= 1.0.0
- Azure CLI
- Active Azure subscription

### Authentication
Required credentials (in secrets.tfvars):
- `subscription_id`: Azure subscription ID
- `tenant_id`: Azure tenant ID
- `jumpbox_admin_username`: Admin username for jumpbox
- `jumpbox_ssh_key`: SSH public key for jumpbox access
- `app_server_admin_username`: Admin username for app server

## Repository Structure

```
opti-infra/
├── terraform/
│   ├── environments/           # Environment-specific configurations
│   │   ├── dev/
│   │   ├── test/
│   │   └── prod/
│   ├── modules/                # Reusable Terraform modules
│   │   └── networking/
│   ├── secrets/                # Sensitive configuration (gitignored)
│   ├── templates/              # Configuration templates
│   ├── userdata/               # Initialization scripts
│   └── main.tf                 # Primary Terraform configuration
```

## Deployment Instructions

### 1. Prepare Secrets Configuration

1. Navigate to the secrets directory:
   ```bash
   cd terraform/secrets
   ```

2. Copy the secrets template:
   ```bash
   cp secrets.tfvars.example secrets.tfvars
   ```

3. Edit `secrets.tfvars` with your Azure-specific values:
   ```bash
   nano secrets.tfvars
   ```

#### Required Configuration Values
- **Azure Authentication**
  - `subscription_id`: Your Azure subscription ID
  - `tenant_id`: Your Azure tenant ID

- **VM Access**
  - `jumpbox_admin_username`: Jumpbox admin username
  - `jumpbox_ssh_key`: Jumpbox SSH public key
  - `app_server_admin_username`: App server admin username
  - `app_server_ssh_key`: App server SSH public key

- **Key Vault Access**
  - `key_vault_object_id`: Key Vault access object ID

#### Optional Configuration
- Storage access keys
- Email service credentials

### 2. Initialize Terraform

```bash
# Navigate to terraform directory
cd terraform

# Initialize Terraform
terraform init
```

### 3. Select Environment Workspace

```bash
# Create and select workspace
terraform workspace new dev
terraform workspace select dev
```

### 4. Plan Infrastructure

```bash
# Review planned changes
terraform plan \
  -var-file="environments/dev/terraform.tfvars" \
  -var-file="secrets/secrets.tfvars"
```

### 5. Apply Infrastructure

```bash
# Deploy infrastructure
terraform apply \
  -var-file="environments/dev/terraform.tfvars" \
  -var-file="secrets/secrets.tfvars"
```

## Environment Management

### Workspace Commands

```bash
# Development Environment
terraform workspace new dev
terraform workspace select dev
terraform plan -var-file="environments/dev/terraform.tfvars"

# Testing Environment
terraform workspace new test
terraform workspace select test
terraform plan -var-file="environments/test/terraform.tfvars"

# Production Environment
terraform workspace new prod
terraform workspace select prod
terraform plan -var-file="environments/prod/terraform.tfvars"
```

## Destroying Infrastructure

⚠️ **Caution**: This will remove all resources in the current workspace.

```bash
terraform destroy \
  -var-file="environments/dev/terraform.tfvars" \
  -var-file="secrets/secrets.tfvars"
```

## Security Guidelines

1. Never commit `secrets.tfvars` to version control
2. Use strong, unique passwords
3. Regularly rotate access keys
4. Limit SSH access to trusted IP ranges
5. Monitor Key Vault and storage account logs


## Azure-Specific Maintenance Recommendations

- Monitor NAT Gateway allocation and scaling
- Review Network Security Group rules regularly
- Track VM performance metrics
- Monitor public IP address usage
- Audit Key Vault access logs
- Regular review of RBAC assignments

## Support

For infrastructure support or questions about the Azure migration, please contact the DevOps team.


terraform/app_gateway.tf

# Create Storage Account for logs (equivalent to S3 bucket)
resource "azurerm_storage_account" "logs" {
  name                     = replace("${local.prefix}logs", "-", "")  # Storage account name can't have hyphens
  resource_group_name      = module.networking.resource_group_name
  location                = module.networking.resource_group_location
  account_tier            = "Standard"
  account_replication_type = "LRS"

  tags = {
    Name = "${local.prefix}-logs-storage"
  }
}

# Create container for logs (equivalent to S3 bucket folder)
resource "azurerm_storage_container" "logs" {
  name                  = "applogs"
  storage_account_name  = azurerm_storage_account.logs.name
  container_access_type = "private"
}

# Public IP for Application Gateway
resource "azurerm_public_ip" "agw" {
  name                = "${local.prefix}-agw-ip"
  resource_group_name = module.networking.resource_group_name
  location            = module.networking.resource_group_location
  allocation_method   = "Static"
  sku                 = "Standard"

  tags = {
    Name = "${local.prefix}-agw-ip"
  }
}

# Application Gateway (equivalent to ALB)
resource "azurerm_application_gateway" "app_gateway" {
  name                = "${local.prefix}-app-gateway"
  resource_group_name = module.networking.resource_group_name
  location            = module.networking.resource_group_location

  sku {
    name     = "WAF_v2"
    tier     = "WAF_v2"
    capacity = 2
  }

  gateway_ip_configuration {
    name      = "gateway-ip-config"
    subnet_id = module.networking.vm_subnet_id["1"]
  }

  frontend_port {
    name = "https-port"
    port = 443
  }

  frontend_port {
    name = "http-port"
    port = 80
  }

  frontend_ip_configuration {
    name                 = "frontend-ip-config"
    public_ip_address_id = azurerm_public_ip.agw.id
  }

  # SSL Certificate from Key Vault
  ssl_certificate {
    name                = "app-gateway-cert"
    key_vault_secret_id = azurerm_key_vault_certificate.app_gateway_cert.secret_id
  }

  backend_address_pool {
    name = "${local.prefix}-backend-pool"
  }

  backend_http_settings {
    name                  = "http-settings"
    cookie_based_affinity = "Disabled"
    port                  = 80
    protocol             = "Http"
    request_timeout      = 60
    path                 = "/"
    probe_name           = "health-probe"
  }

  probe {
    name                = "health-probe"
    host                = "127.0.0.1"
    interval            = 60
    timeout             = 5
    path                = "/"
    unhealthy_threshold = 3
    protocol            = "Http"
    match {
      status_code = ["200"]
    }
  }

  http_listener {
    name                           = "https-listener"
    frontend_ip_configuration_name = "frontend-ip-config"
    frontend_port_name            = "https-port"
    protocol                      = "Https"
    ssl_certificate_name          = "app-gateway-cert"
  }

  http_listener {
    name                           = "http-listener"
    frontend_ip_configuration_name = "frontend-ip-config"
    frontend_port_name            = "http-port"
    protocol                      = "Http"
  }

  redirect_configuration {
    name                 = "http-to-https"
    redirect_type        = "Permanent"
    target_listener_name = "https-listener"
    include_path         = true
    include_query_string = true
  }

  request_routing_rule {
    name                        = "http-to-https-rule"
    rule_type                  = "Basic"
    http_listener_name         = "http-listener"
    redirect_configuration_name = "http-to-https"
    priority                   = 2
  }

  request_routing_rule {
    name                       = "https-rule"
    rule_type                  = "Basic"
    http_listener_name         = "https-listener"
    backend_address_pool_name  = "${local.prefix}-backend-pool"
    backend_http_settings_name = "http-settings"
    priority                   = 1
  }

  # Enable logging
  diagnostic_setting {
    name                       = "app-gateway-logs"
    target_resource_id        = azurerm_storage_account.logs.id
    storage_account_id        = azurerm_storage_account.logs.id

    enabled_log {
      category = "ApplicationGatewayAccessLog"
    }
    enabled_log {
      category = "ApplicationGatewayPerformanceLog"
    }
    enabled_log {
      category = "ApplicationGatewayFirewallLog"
    }
  }

  ssl_policy {
    policy_type = "Predefined"
    policy_name = "AppGwSslPolicy20170401S"  # Or a more recent policy
  }

  waf_configuration {
    enabled                  = true
    firewall_mode           = "Prevention"
    rule_set_type          = "OWASP"
    rule_set_version       = "3.2"
    file_upload_limit_mb   = 100
    max_request_body_size_kb = 128
  }

  tags = {
    Name = "${local.prefix}-app-gateway"
  }

  depends_on = [
    azurerm_linux_virtual_machine.app_server,
    azurerm_storage_account.logs
  ]
}

# DNS Record (similar to Route53)
resource "azurerm_dns_cname_record" "app" {
  name                = "app"
  zone_name           = azurerm_dns_zone.oi_portal.name
  resource_group_name = module.networking.resource_group_name
  ttl                 = 60
  record             = azurerm_public_ip.agw.fqdn

  tags = {
    Name = "${local.prefix}-app-dns"
  }
}


terraform/app_server.tf

# Network Security Group (NSG) for app server
# This is equivalent to AWS Security Group (aws_security_group)
# In Azure, NSGs can be attached to subnets or network interfaces
resource "azurerm_network_security_group" "appserver_nsg" {
  name                = "${local.prefix}-appserver-nsg"
  location            = module.networking.resource_group_location
  resource_group_name = module.networking.resource_group_name

  # Allow HTTPS inbound - Port 443
  # Equivalent to aws_vpc_security_group_ingress_rule for HTTPS
  security_rule {
    name                       = "AllowHTTPS"
    priority                   = 1001  # Lower number = higher priority
    direction                  = "Inbound"
    access                     = "Allow"
    protocol                   = "Tcp"
    source_port_range         = "*"
    destination_port_range    = "443"
    source_address_prefix     = "*"
    destination_address_prefix = "*"
  }

  # Allow all internal communication
  # Equivalent to aws_vpc_security_group_ingress_rule for internal traffic
  security_rule {
    name                       = "AllowInternalAll"
    priority                   = 1002
    direction                  = "Inbound"
    access                     = "Allow"
    protocol                   = "*"  # All protocols
    source_port_range         = "*"
    destination_port_range    = "*"
    source_address_prefix     = "VirtualNetwork"  # Only within VNet
    destination_address_prefix = "VirtualNetwork"
  }

  tags = {
    Name = "${local.prefix}-appserver-nsg"
  }
}

# Network Interface for app server
# This is the Azure equivalent of AWS ENI (Elastic Network Interface)
resource "azurerm_network_interface" "app_server_nic" {
  name                = "${local.prefix}-appserver-nic"
  location            = module.networking.resource_group_location
  resource_group_name = module.networking.resource_group_name

  ip_configuration {
    name                          = "internal"
    subnet_id                     = module.networking.vm_subnet_id["1"]  # Using first AZ
    private_ip_address_allocation = "Dynamic"  # Similar to AWS auto-assign
  }

  tags = {
    Name = "${local.prefix}-appserver-nic"
  }
}

# Associate NSG with Network Interface
# In AWS this is handled automatically by the security group association
resource "azurerm_network_interface_security_group_association" "app_nsg_association" {
  network_interface_id      = azurerm_network_interface.app_server_nic.id
  network_security_group_id = azurerm_network_security_group.appserver_nsg.id
}

# App Server Virtual Machine
# This replaces the aws_instance resource
resource "azurerm_linux_virtual_machine" "app_server" {
  name                = "${local.prefix}-appserver"
  resource_group_name = module.networking.resource_group_name
  location            = module.networking.resource_group_location
  size                = "Standard_D8ps_v5"  # ARM-based VM, equivalent to t4g.2xlarge
  admin_username      = var.app_server_admin_username

  # Network interface attachment
  network_interface_ids = [
    azurerm_network_interface.app_server_nic.id
  ]

  # SSH key configuration
  # Equivalent to key_name in AWS
  admin_ssh_key {
    username   = var.app_server_admin_username
    public_key = tls_private_key.internal_key.public_key_openssh
  }

  # OS Disk Configuration
  # Equivalent to root_block_device in AWS
  os_disk {
    name                 = "${local.prefix}-appserver-os-disk"
    caching              = "ReadWrite"
    storage_account_type = "Premium_LRS"  # Premium SSD for better performance
    disk_size_gb         = 50  # Same as AWS configuration

    tags = {
      Name = "${local.prefix}-app_server-root-disk"
    }
  }

  # VM Image Configuration
  # Equivalent to AMI in AWS
  source_image_reference {
    publisher = "RedHat"
    offer     = "RHEL"
    sku       = "8-gen2"
    version   = "latest"
  }

  # User data script
  # Same functionality as AWS user_data
  custom_data = base64encode(file("userdata/appserver-init.sh"))

  tags = {
    Name          = "${local.prefix}-appserver-instance"
    ansible_group = "appserver"
  }
}

# Managed Disk for Database
# Equivalent to aws_ebs_volume
resource "azurerm_managed_disk" "db_disk" {
  name                 = "${local.prefix}-db-disk"
  location            = module.networking.resource_group_location
  resource_group_name = module.networking.resource_group_name
  storage_account_type = "Premium_LRS"  # Premium SSD for database performance
  create_option        = "Empty"
  disk_size_gb         = 100  # Same size as AWS EBS volume

  tags = {
    Name = "${local.prefix}-appserver-db-disk"
  }
}

# Attach Data Disk to VM
# Equivalent to aws_volume_attachment
resource "azurerm_virtual_machine_data_disk_attachment" "db_disk_attachment" {
  managed_disk_id    = azurerm_managed_disk.db_disk.id
  virtual_machine_id = azurerm_linux_virtual_machine.app_server.id
  lun                = "10"  # Logical Unit Number for disk identification
  caching            = "ReadWrite"
}

# Storage Account for Backups
# Equivalent to S3 bucket for backups
resource "azurerm_storage_account" "backup_storage" {
  name                     = replace("${local.prefix}backups", "-", "")  # Storage account names can't have hyphens
  resource_group_name      = module.networking.resource_group_name
  location                = module.networking.resource_group_location
  account_tier            = "Standard"
  account_replication_type = "GRS"  # Geo-redundant storage for backup safety

  tags = {
    Name = "${local.prefix}-backups-storage"
  }
}

# Storage Account for Application Data
# Equivalent to S3 bucket for application data
resource "azurerm_storage_account" "app_data_storage" {
  name                     = replace("${local.prefix}appdata", "-", "")
  resource_group_name      = module.networking.resource_group_name
  location                = module.networking.resource_group_location
  account_tier            = "Standard"
  account_replication_type = "LRS"  # Locally redundant storage for app data

  tags = {
    Name = "${local.prefix}-app-data-storage"
  }
}

# Storage Containers
# Equivalent to S3 bucket folder/prefix
resource "azurerm_storage_container" "backup_container" {
  name                  = "backups"
  storage_account_name  = azurerm_storage_account.backup_storage.name
  container_access_type = "private"  # Private access only
}

resource "azurerm_storage_container" "app_data_container" {
  name                  = "appdata"
  storage_account_name  = azurerm_storage_account.app_data_storage.name
  container_access_type = "private"  # Private access only
}

# Application Gateway Backend Pool Association
# Equivalent to aws_lb_target_group_attachment
resource "azurerm_application_gateway_backend_address_pool_address" "app_server" {
  name                    = "${local.prefix}-app-server"
  backend_address_pool_id = azurerm_application_gateway.app_gateway.backend_address_pool[0].id
  ip_address              = azurerm_network_interface.app_server_nic.private_ip_address
}


terraform/certs.tf

# In AWS, we used Route53 for DNS and ACM for certificates
# In Azure, we use Azure DNS and Key Vault for certificates

# Create/Import DNS Zone
# AWS: aws_route53_zone
# Azure: azurerm_dns_zone
resource "azurerm_dns_zone" "oi_portal" {
  name                = "oi-portal.com"
  resource_group_name = module.networking.resource_group_name

  tags = {
    Name = "${local.prefix}-dns-zone"
  }
}

# Import existing DNS zone
# AWS: Used Route53 zone ID directly
# Azure: Uses full resource path including subscription and resource group
import {
  to = azurerm_dns_zone.oi_portal
  id = "/subscriptions/${var.subscription_id}/resourceGroups/${module.networking.resource_group_name}/providers/Microsoft.Network/dnszones/oi-portal.com"
}

# Generate SSL Certificate
# AWS: Used ACM (aws_acm_certificate)
# Azure: Uses Key Vault Certificate with more detailed configuration
resource "azurerm_key_vault_certificate" "oi_portal_cert" {
  name         = "${local.prefix}-oi-portal-cert"
  key_vault_id = azurerm_key_vault.vault.id

  certificate_policy {
    # Issuer configuration - Self-signed in this case
    # In AWS, this was handled automatically by ACM
    issuer_parameters {
      name = "Self"
    }

    # Key configuration - Not explicitly required in AWS ACM
    key_properties {
      exportable = true      # Allow export of the certificate
      key_size   = 2048      # Standard RSA key size
      key_type   = "RSA"     # Using RSA encryption
      reuse_key  = true      # Reuse key on renewal
    }

    # Auto-renewal configuration - AWS ACM handled this automatically
    lifetime_action {
      action {
        action_type = "AutoRenew"
      }

      trigger {
        days_before_expiry = 30  # Start renewal process 30 days before expiry
      }
    }

    # Certificate content type
    secret_properties {
      content_type = "application/x-pkcs12"  # Standard format for certificates
    }

    # Certificate properties
    # AWS ACM simplified this, but Azure needs explicit configuration
    x509_certificate_properties {
      # Extended Key Usage for server authentication
      # 1.3.6.1.5.5.7.3.1 = Server Authentication
      extended_key_usage = ["1.3.6.1.5.5.7.3.1"]

      # Define how the certificate can be used
      key_usage = [
        "digitalSignature",
        "keyEncipherment"
      ]

      subject            = "CN=oi-portal.com"
      validity_in_months = 12  # 1 year validity

      # Same as AWS subject_alternative_names
      subject_alternative_names {
        dns_names = ["oi-portal.com", "*.oi-portal.com"]
      }
    }
  }

  tags = {
    Name = "${local.prefix}-oi-portal-cert"
  }
}

# DNS Validation Record
# AWS: Used aws_route53_record with values from ACM
# Azure: Uses TXT record with Key Vault certificate name
resource "azurerm_dns_txt_record" "cert_validation" {
  name                = "@"
  zone_name           = azurerm_dns_zone.oi_portal.name
  resource_group_name = module.networking.resource_group_name
  ttl                 = 300  # Same as AWS configuration

  record {
    # Azure format for certificate validation
    value = "MS=ms${azurerm_key_vault_certificate.oi_portal_cert.name}"
  }

  tags = {
    Name = "${local.prefix}-cert-validation"
  }
}

# Application Gateway Certificate
# This is Azure-specific as we need a separate certificate for Application Gateway
# In AWS, we could use the same ACM certificate for ALB
resource "azurerm_key_vault_certificate" "app_gateway_cert" {
  name         = "${local.prefix}-app-gateway-cert"
  key_vault_id = azurerm_key_vault.vault.id

  certificate_policy {
    issuer_parameters {
      name = "Self"
    }

    key_properties {
      exportable = true
      key_size   = 2048
      key_type   = "RSA"
      reuse_key  = true
    }

    lifetime_action {
      action {
        action_type = "AutoRenew"
      }

      trigger {
        days_before_expiry = 30
      }
    }

    secret_properties {
      content_type = "application/x-pkcs12"
    }

    x509_certificate_properties {
      extended_key_usage = ["1.3.6.1.5.5.7.3.1"]
      key_usage = [
        "digitalSignature",
        "keyEncipherment"
      ]
      subject            = "CN=*.oi-portal.com"
      validity_in_months = 12

      subject_alternative_names {
        dns_names = ["*.oi-portal.com"]
      }
    }
  }

  tags = {
    Name = "${local.prefix}-app-gateway-cert"
  }
}

# Outputs
# Additional outputs needed for Azure integration
output "certificate_thumbprint" {
  value = azurerm_key_vault_certificate.oi_portal_cert.thumbprint
}

output "dns_zone_nameservers" {
  value = azurerm_dns_zone.oi_portal.name_servers
}


terraform/internal_key_pair.tf

# Create an internal key pair that can be used as a method to connect between internal nodes.
# The corresponding private key will also be uploaded to the jumpbox instance so that we
# can access other nodes inside the jumpbox

# Generate the RSA key
resource "tls_private_key" "internal_key" {
  algorithm = "RSA"
  rsa_bits  = 4096
}

# Store the private key locally for SSH access
resource "local_sensitive_file" "private_key" {
  filename        = pathexpand("~/.ssh/oii-internal-key-rsa")
  content         = tls_private_key.internal_key.private_key_openssh
  file_permission = "0600"
}

# Store the private key in ansible directory
resource "local_sensitive_file" "private_key_ansible" {
  filename        = "${path.module}/../playbooks/oii-internal-key-rsa"
  content         = tls_private_key.internal_key.private_key_openssh
  file_permission = "0600"
}

# Store public key in Key Vault for secure access
resource "azurerm_key_vault_secret" "internal_ssh_key" {
  name         = "internal-ssh-private-key"
  value        = tls_private_key.internal_key.private_key_openssh
  key_vault_id = azurerm_key_vault.vault.id  # Reference to your Key Vault

  tags = {
    environment = var.env
    purpose     = "internal-ssh"
  }
}

# Store public key in Key Vault
resource "azurerm_key_vault_secret" "internal_ssh_public_key" {
  name         = "internal-ssh-public-key"
  value        = tls_private_key.internal_key.public_key_openssh
  key_vault_id = azurerm_key_vault.vault.id  # Reference to your Key Vault

  tags = {
    environment = var.env
    purpose     = "internal-ssh"
  }
}

# Output the public key for reference
output "internal_public_key" {
  value     = tls_private_key.internal_key.public_key_openssh
  sensitive = true
}


terraform/jumpbox.tf

# Public IP for jumpbox - conditionally created
resource "azurerm_public_ip" "jumpbox_ip" {
  count               = var.jumpbox_enable_public_ip ? 1 : 0
  name                = "${local.prefix}-jumpbox-ip"
  resource_group_name = module.networking.resource_group_name
  location            = module.networking.resource_group_location
  allocation_method   = "Static"
  sku                = "Standard"
  
  tags = merge(
    {
      Name = "${local.prefix}-jumpbox-ip"
    },
    var.jumpbox_tags
  )
}

# Network Security Group for jumpbox
resource "azurerm_network_security_group" "jumpbox_nsg" {
  name                = "${local.prefix}-jumpbox-nsg"
  location            = module.networking.resource_group_location
  resource_group_name = module.networking.resource_group_name

  security_rule {
    name                       = "SSH"
    priority                   = 1001
    direction                  = "Inbound"
    access                     = "Allow"
    protocol                   = "Tcp"
    source_port_range         = "*"
    destination_port_range    = "22"
    source_address_prefix     = "*"
    destination_address_prefix = "*"
  }

  tags = merge(
    {
      Name = "${local.prefix}-jumpbox-nsg"
    },
    var.jumpbox_tags
  )
}

# Network interface for jumpbox
resource "azurerm_network_interface" "jumpbox_nic" {
  name                = "${local.prefix}-jumpbox-nic"
  location            = module.networking.resource_group_location
  resource_group_name = module.networking.resource_group_name

  ip_configuration {
    name                          = "jumpbox-ipconfig"
    subnet_id                     = module.networking.vm_subnet_id[var.jumpbox_subnet_zone]
    private_ip_address_allocation = "Dynamic"
    public_ip_address_id          = var.jumpbox_enable_public_ip ? azurerm_public_ip.jumpbox_ip[0].id : null
  }

  tags = merge(
    {
      Name = "${local.prefix}-jumpbox-nic"
    },
    var.jumpbox_tags
  )
}

# Jumpbox VM
resource "azurerm_linux_virtual_machine" "jumpbox" {
  name                = "${local.prefix}-jumpbox-instance"
  resource_group_name = module.networking.resource_group_name
  location            = module.networking.resource_group_location
  size                = var.jumpbox_size
  
  admin_username      = var.jumpbox_admin_username
  disable_password_authentication = true

  admin_ssh_key {
    username   = var.jumpbox_admin_username
    public_key = var.jumpbox_ssh_key
  }

  network_interface_ids = [
    azurerm_network_interface.jumpbox_nic.id
  ]

  os_disk {
    name                 = "${local.prefix}-jumpbox-root-disk"
    caching              = "ReadWrite"
    storage_account_type = var.jumpbox_os_disk_type
    disk_size_gb         = var.jumpbox_os_disk_size

    tags = merge(
      {
        Name = "${local.prefix}-jumpbox-root-ebs"
      },
      var.jumpbox_tags
    )
  }

  source_image_reference {
    publisher = "RedHat"
    offer     = "RHEL"
    sku       = "8-gen2"
    version   = var.jumpbox_image_version
  }

  plan {
    name      = "8-gen2"
    product   = "rhel"
    publisher = "RedHat"
  }

  custom_data = base64encode(templatefile("${path.module}/userdata/jumpbox-init.sh.tftpl", {
    key_mat = tls_private_key.internal_key.private_key_openssh
  }))

  tags = merge(
    {
      Name           = "${local.prefix}-jumpbox-instance"
      ansible_group  = "bastion"
    },
    var.jumpbox_tags
  )

  depends_on = [
    tls_private_key.internal_key,
  ]
}

resource "azurerm_network_interface_security_group_association" "jumpbox_nsg_association" {
  network_interface_id      = azurerm_network_interface.jumpbox_nic.id
  network_security_group_id = azurerm_network_security_group.jumpbox_nsg.id
}


terraform/key_vault.tf

# Create Azure Key Vault for storing sensitive information
resource "azurerm_key_vault" "vault" {
  name                        = "${var.prefix}-${var.env}-vault"
  location                    = module.networking.resource_group_location
  resource_group_name         = module.networking.resource_group_name
  enabled_for_disk_encryption = true
  tenant_id                   = data.azurerm_client_config.current.tenant_id
  soft_delete_retention_days  = 7
  purge_protection_enabled    = false

  sku_name = "standard"

  # Allow the currently authenticated Azure CLI user to manage the Key Vault
  access_policy {
    tenant_id = data.azurerm_client_config.current.tenant_id
    object_id = data.azurerm_client_config.current.object_id

    key_permissions = [
      "Get", "List", "Create", "Delete", "Update",
    ]

    secret_permissions = [
      "Get", "List", "Set", "Delete",
    ]
  }

  # Add access policy for the jumpbox's managed identity (if using)
  dynamic "access_policy" {
    for_each = var.env == "prod" ? [1] : []  # Only in prod
    content {
      tenant_id = data.azurerm_client_config.current.tenant_id
      object_id = azurerm_linux_virtual_machine.jumpbox.identity[0].principal_id

      secret_permissions = [
        "Get", "List",
      ]
    }
  }

  tags = {
    environment = var.env
    purpose     = "key-management"
  }
}

# Get the current Azure CLI credentials
data "azurerm_client_config" "current" {}


terraform/main.tf

# Configure Azure Provider
terraform {
  required_providers {
    azurerm = {
      source  = "hashicorp/azurerm"
      version = "~> 3.0"
    }
    random = {
      source  = "hashicorp/random"
      version = "~> 3.0"
    }
  }

  # Backend configuration - this should be different for each environment
  backend "azurerm" {
    # These values should be overridden by backend configuration in each environment
  }
}

provider "azurerm" {
  features {}

  # If using different subscriptions per environment, these can be set via variables
  subscription_id = var.subscription_id
  tenant_id       = var.tenant_id
}

# Networking module with environment-specific variables
module "networking" {
  source = "./modules/networking"

  # Pass through environment-specific variables
  resource_group_name = var.resource_group_name
  location           = var.location
  env                = var.env
  prefix             = var.prefix
  redundancy         = var.redundancy
}

# Root level local variables
locals {
  common_tags = {
    Environment = var.env
    Project     = var.product
    ManagedBy   = "Terraform"
  }
}






















terraform/outputs.tf

output "jumpbox_public_ip" {
  value = azurerm_public_ip.jumpbox_ip.ip_address
}

output "app_server_private_ip" {
  value = azurerm_network_interface.app_server_nic.private_ip_address
  description = "Private IP of the app server"
}

# Add key outputs (sensitive)
output "jumpbox_private_key" {
  value     = tls_private_key.jumpbox_key.private_key_pem
  sensitive = true
}

output "app_server_private_key" {
  value     = tls_private_key.app_server_key.private_key_pem
  sensitive = true
}

resource "local_file" "ansible_inventory" {
  filename = "${path.module}/inventory.ini"
  content  = templatefile("${path.module}/templates/inventory.ini.tftpl", {
    jumpbox_public_ip     = azurerm_public_ip.jumpbox_ip.ip_address
    app_server_private_ip = azurerm_network_interface.app_server_nic.private_ip_address
    worker_private_ips    = []  # Add worker IPs if you have any
    jumpbox_admin_username = var.jumpbox_admin_username
    app_server_admin_username = var.app_server_admin_username
  })
}





terraform/variables.tf

variable "subscription_id" {
  type        = string
  description = "The Azure subscription ID"
}

variable "tenant_id" {
  type        = string
  description = "The Azure tenant ID"
}

variable "product" {
  type        = string
  description = "Product name for resource naming"
}

variable "env" {
  type        = string
  description = "Environment name (dev, test, prod)"
}

variable "location" {
  type        = string
  description = "Azure region for resource deployment"
}

variable "resource_group_name" {
  type        = string
  description = "Name of the resource group"
}

variable "prefix" {
  type        = string
  description = "Prefix for resource naming"
}

variable "redundancy" {
  type        = number
  description = "Number of availability zones (1-3)"
  default     = 2
  validation {
    condition     = var.redundancy >= 1 && var.redundancy <= 3
    error_message = "Redundancy must be between 1 and 3."
  }
}

variable "jumpbox_size" {
  type        = string
  description = "The size of the jumpbox VM"
  default     = "Standard_B1s"
}

variable "jumpbox_admin_username" {
  type        = string
  description = "The admin username for the jumpbox"
}

variable "jumpbox_ssh_key" {
  type        = string
  description = "SSH public key for jumpbox access"
}

variable "jumpbox_os_disk_size" {
  type        = number
  description = "The size of the jumpbox OS disk in GB"
  default     = 25
}

variable "jumpbox_os_disk_type" {
  type        = string
  description = "The type of OS disk (e.g., Standard_LRS, Premium_LRS)"
  default     = "Standard_LRS"
}

variable "jumpbox_image_version" {
  type        = string
  description = "The version of the RHEL image to use"
  default     = "latest"
}

variable "jumpbox_enable_public_ip" {
  type        = bool
  description = "Whether to enable public IP for jumpbox"
  default     = true
}

variable "jumpbox_subnet_zone" {
  type        = string
  description = "The availability zone for the jumpbox subnet"
  default     = "1"
}

variable "jumpbox_tags" {
  type        = map(string)
  description = "Additional tags for the jumpbox resources"
  default     = {}
}


terraform/environments/dev/backend.tf

terraform {
  backend "azurerm" {
    resource_group_name  = "terraform-state-rg"
    storage_account_name = "oiitfstatedev"
    container_name      = "tfstate"
    key                 = "dev.terraform.tfstate"
  }
}


terraform/environments/dev/terraform.tfvars.example

# Copy this file to terraform.tfvars and update values as needed
# General
environment           = "dev"
location             = "eastus"
resource_group_name  = "oii-dev-rg"
prefix               = "oii"
product              = "oii"
redundancy           = 2

# Network Configuration
address_space        = ["10.0.0.0/16"]
vm_subnet_prefix     = "10.0.1.0/24"
nat_subnet_prefix    = "10.0.2.0/24"

# App Server Configuration
app_server_size           = "Standard_D8ps_v5"
app_server_admin_username = "devadmin"
app_server_os_disk_size   = 50
app_server_data_disk_size = 100

# Jumpbox Configuration
jumpbox_size              = "Standard_B1s"
jumpbox_admin_username    = "devjumpbox"
jumpbox_os_disk_size     = 25
jumpbox_os_disk_type     = "Standard_LRS"

# Application Gateway Configuration
app_gateway_sku_name     = "Standard_v2"
app_gateway_sku_tier     = "Standard_v2"
app_gateway_capacity     = 2

# Storage Configuration
storage_account_tier        = "Standard"
backup_replication_type    = "LRS"
appdata_replication_type   = "LRS"


terraform/environments/prod/backend.tf

terraform {
  backend "azurerm" {
    resource_group_name  = "terraform-state-rg"
    storage_account_name = "oiitfstateprod"
    container_name      = "tfstate"
    key                 = "prod.terraform.tfstate"
  }
}


terraform/environments/prod/terraform.tfvars.example

# Copy this file to terraform.tfvars and update values as needed
# General
environment           = "prod"
location             = "eastus"
resource_group_name  = "oii-prod-rg"
prefix               = "oii"
product              = "oii"
redundancy           = 3

# Network Configuration
address_space        = ["10.2.0.0/16"]
vm_subnet_prefix     = "10.2.1.0/24"
nat_subnet_prefix    = "10.2.2.0/24"

# App Server Configuration
app_server_size           = "Standard_D8ps_v5"
app_server_admin_username = "prodadmin"
app_server_os_disk_size   = 50
app_server_data_disk_size = 100

# Jumpbox Configuration
jumpbox_size              = "Standard_B2s"  # Larger for prod
jumpbox_admin_username    = "prodjumpbox"
jumpbox_os_disk_size     = 50              # Larger for prod
jumpbox_os_disk_type     = "Premium_LRS"   # Premium for prod

# Application Gateway Configuration
app_gateway_sku_name     = "WAF_v2"        # WAF enabled for prod
app_gateway_sku_tier     = "WAF_v2"
app_gateway_capacity     = 3                # Higher capacity for prod

# Storage Configuration
storage_account_tier        = "Premium"
backup_replication_type    = "GRS"         # Geo-redundant for prod
appdata_replication_type   = "ZRS"         # Zone-redundant for prod


terraform/environments/test/backend.tf

terraform {
  backend "azurerm" {
    resource_group_name  = "terraform-state-rg"
    storage_account_name = "oiitfstatetest"
    container_name      = "tfstate"
    key                 = "test.terraform.tfstate"
  }
}


terraform/environments/test/terraform.tfvars.example

# Copy this file to terraform.tfvars and update values as needed
# General
environment           = "test"
location             = "eastus"
resource_group_name  = "oii-test-rg"
prefix               = "oii"
product              = "oii"
redundancy           = 2

# Network Configuration
address_space        = ["10.1.0.0/16"]
vm_subnet_prefix     = "10.1.1.0/24"
nat_subnet_prefix    = "10.1.2.0/24"

# App Server Configuration
app_server_size           = "Standard_D8ps_v5"
app_server_admin_username = "testadmin"
app_server_os_disk_size   = 50
app_server_data_disk_size = 100

# Jumpbox Configuration
jumpbox_size              = "Standard_B1s"
jumpbox_admin_username    = "testjumpbox"
jumpbox_os_disk_size     = 25
jumpbox_os_disk_type     = "Standard_LRS"

# Application Gateway Configuration
app_gateway_sku_name     = "Standard_v2"
app_gateway_sku_tier     = "Standard_v2"
app_gateway_capacity     = 2

# Storage Configuration
storage_account_tier        = "Standard"
backup_replication_type    = "LRS"
appdata_replication_type   = "LRS"



terraform/modules/networking/main.tf

locals {
  base_cidr = "10.0.0.0/16"
  prefix    = var.prefix
  
  # Calculate zones based on redundancy
  az_count          = var.redundancy
  availability_zones = slice(["1", "2", "3"], 0, var.redundancy)
  
  # Calculate subnet bits
  total_subnets     = 2 * local.az_count  # VM and NAT subnet per zone
  new_bits          = ceil(log(local.total_subnets, 2))
}

# Create a resource group
resource "azurerm_resource_group" "main" {
  name     = var.resource_group_name
  location = var.location
  tags = {
    terraform = "true"
    env      = var.env
    prefix   = var.prefix
  }
}

# Create a virtual network
resource "azurerm_virtual_network" "mainvnet" {
  name                = "${var.prefix}-${var.env}-network"
  address_space       = [local.base_cidr]
  location           = azurerm_resource_group.main.location
  resource_group_name = azurerm_resource_group.main.name
  tags = {
    terraform = "true"
    env      = var.env
  }
}

# Create VM subnets
resource "azurerm_subnet" "subnet_with_vm" {
  for_each             = toset(local.availability_zones)
  name                 = "${var.prefix}-${var.env}-vm-sn-${each.value}"
  resource_group_name  = azurerm_resource_group.main.name
  virtual_network_name = azurerm_virtual_network.mainvnet.name
  address_prefixes     = [cidrsubnet(local.base_cidr, local.new_bits, parseint(each.key, 10))]
  service_endpoints    = ["Microsoft.Storage"]
}

# Create NAT subnets
resource "azurerm_subnet" "subnet_with_nat" {
  for_each             = toset(local.availability_zones)
  name                 = "${var.prefix}-${var.env}-nat-sn-${each.value}"
  resource_group_name  = azurerm_resource_group.main.name
  virtual_network_name = azurerm_virtual_network.mainvnet.name
  address_prefixes     = [cidrsubnet(local.base_cidr, local.new_bits, parseint(each.key, 10) + local.az_count)]
  service_endpoints    = ["Microsoft.Storage"]
}

# Create NAT Gateway
resource "azurerm_nat_gateway" "nat_gateway" {
  for_each            = toset(local.availability_zones)
  name                = "${var.prefix}-${var.env}-nat-gw-${each.value}"
  location            = azurerm_resource_group.main.location
  resource_group_name = azurerm_resource_group.main.name
  sku_name            = "Standard"
  tags = {
    terraform = "true"
    env      = var.env
  }
}

# Create public IPs for NAT Gateway
resource "azurerm_public_ip" "nat_ip" {
  for_each            = toset(local.availability_zones)
  name                = "${var.prefix}-${var.env}-nat-ip-${each.value}"
  location            = azurerm_resource_group.main.location
  resource_group_name = azurerm_resource_group.main.name
  allocation_method   = "Static"
  sku                 = "Standard"
  tags = {
    terraform = "true"
    env      = var.env
  }
}

# Associate public IPs with NAT Gateway
resource "azurerm_nat_gateway_public_ip_association" "nat_ip_assoc" {
  for_each            = toset(local.availability_zones)
  nat_gateway_id      = azurerm_nat_gateway.nat_gateway[each.value].id
  public_ip_address_id = azurerm_public_ip.nat_ip[each.value].id
  # nat_gateway_id       = azurerm_nat_gateway.nat_gateway.id
  # public_ip_address_id = azurerm_public_ip.nat_ip.id
}

# Associate NAT Gateway with subnet
resource "azurerm_subnet_nat_gateway_association" "subnet_nat_assoc" {
  for_each       = toset(local.availability_zones)
  subnet_id      = azurerm_subnet.subnet_with_nat[each.value].id
  nat_gateway_id = azurerm_nat_gateway.nat_gateway[each.value].id
  # subnet_id      = azurerm_subnet.subnet_with_nat.id
  # subnet_id = azurerm_subnet.subnet_with_nat["1"].id
  # nat_gateway_id = azurerm_nat_gateway.nat_gateway.id
}

# VNet-level Network Security Group
resource "azurerm_network_security_group" "vnet_nsg" {
  name                = "${var.prefix}-${var.env}-vnet-nsg"
  location            = azurerm_resource_group.main.location
  resource_group_name = azurerm_resource_group.main.name

  # Allow HTTPS inbound
  security_rule {
    name                       = "AllowHTTPS"
    priority                   = 100
    direction                  = "Inbound"
    access                     = "Allow"
    protocol                   = "Tcp"
    source_port_range         = "*"
    destination_port_range    = "443"
    source_address_prefix     = "*"
    destination_address_prefix = "*"
  }

  # Allow HTTP inbound (for redirection to HTTPS)
  security_rule {
    name                       = "AllowHTTP"
    priority                   = 110
    direction                  = "Inbound"
    access                     = "Allow"
    protocol                   = "Tcp"
    source_port_range         = "*"
    destination_port_range    = "80"
    source_address_prefix     = "*"
    destination_address_prefix = "*"
  }

  # Allow SSH only from specific IPs (you should restrict this)
  security_rule {
    name                       = "AllowSSH"
    priority                   = 120
    direction                  = "Inbound"
    access                     = "Allow"
    protocol                   = "Tcp"
    source_port_range         = "*"
    destination_port_range    = "22"
    source_address_prefix     = "*"  # Should be restricted to your IP range
    destination_address_prefix = "*"
  }

  # Deny all other inbound traffic
  security_rule {
    name                       = "DenyAllInbound"
    priority                   = 4096
    direction                  = "Inbound"
    access                     = "Deny"
    protocol                   = "*"
    source_port_range         = "*"
    destination_port_range    = "*"
    source_address_prefix     = "*"
    destination_address_prefix = "*"
  }

  tags = {
    terraform = "true"
    env      = var.env
  }
}

# Subnet-specific NSGs
resource "azurerm_network_security_group" "vm_subnet_nsg" {
  for_each            = toset(local.availability_zones)
  name                = "${var.prefix}-${var.env}-vm-subnet-nsg-${each.value}"
  location            = azurerm_resource_group.main.location
  resource_group_name = azurerm_resource_group.main.name

  # Allow inbound from App Gateway
  security_rule {
    name                       = "AllowAppGatewayInbound"
    priority                   = 100
    direction                  = "Inbound"
    access                     = "Allow"
    protocol                   = "Tcp"
    source_port_range         = "*"
    destination_port_range    = "80"
    source_address_prefix     = "GatewayManager"
    destination_address_prefix = "*"
  }

  # Allow internal communication
  security_rule {
    name                       = "AllowVnetInbound"
    priority                   = 110
    direction                  = "Inbound"
    access                     = "Allow"
    protocol                   = "*"
    source_port_range         = "*"
    destination_port_range    = "*"
    source_address_prefix     = "VirtualNetwork"
    destination_address_prefix = "VirtualNetwork"
  }

  tags = {
    terraform = "true"
    env      = var.env
  }
}

# NSG for private subnets (NAT subnets)
resource "azurerm_network_security_group" "nat_subnet_nsg" {
  for_each            = toset(local.availability_zones)
  name                = "${var.prefix}-${var.env}-nat-subnet-nsg-${each.value}"
  location            = azurerm_resource_group.main.location
  resource_group_name = azurerm_resource_group.main.name

  # Allow internal communication only
  security_rule {
    name                       = "AllowVnetInbound"
    priority                   = 100
    direction                  = "Inbound"
    access                     = "Allow"
    protocol                   = "*"
    source_port_range         = "*"
    destination_port_range    = "*"
    source_address_prefix     = "VirtualNetwork"
    destination_address_prefix = "VirtualNetwork"
  }

  # Deny all other inbound
  security_rule {
    name                       = "DenyAllInbound"
    priority                   = 4096
    direction                  = "Inbound"
    access                     = "Deny"
    protocol                   = "*"
    source_port_range         = "*"
    destination_port_range    = "*"
    source_address_prefix     = "*"
    destination_address_prefix = "*"
  }

  tags = {
    terraform = "true"
    env      = var.env
  }
}

# Associate NSGs with subnets
resource "azurerm_subnet_network_security_group_association" "vm_subnet_nsg_assoc" {
  for_each                  = toset(local.availability_zones)
  subnet_id                 = azurerm_subnet.subnet_with_vm[each.value].id
  network_security_group_id = azurerm_network_security_group.vm_subnet_nsg[each.value].id
}

resource "azurerm_subnet_network_security_group_association" "nat_subnet_nsg_assoc" {
  for_each                  = toset(local.availability_zones)
  subnet_id                 = azurerm_subnet.subnet_with_nat[each.value].id
  network_security_group_id = azurerm_network_security_group.nat_subnet_nsg[each.value].id
}


terraform/modules/networking/outputs.tf

# outputs.tf

# Resource Group outputs - Required in Azure (no AWS equivalent)
# These are necessary as Azure requires resource group management
output "resourcegroup_id" {
  value       = azurerm_resource_group.main.id
  description = "The resource group id of the resource group being created by this module"
}

output "resource_group_location" {
  value       = azurerm_resource_group.main.location
  description = "The resource group location of the resource group being created by this module"
}

output "resource_group_name" {
  value       = azurerm_resource_group.main.name
  description = "The resource group name of the resource group being created by this module"
}

# Virtual Network ID - Equivalent to AWS VPC ID
# Maintained for consistent network resource referencing across cloud providers
output "vpc_id" {
  value       = azurerm_virtual_network.mainvnet.id
  description = "The virtual network id of the VNet being created by this module"
}

# Subnet IDs - Using map format for Azure's zone-based architecture
# Changed from AWS array format [*].id to Azure map format for better zone mapping
# This change reflects Azure's different availability zone handling (numeric vs named)
output "vm_subnet_id" {
  value = {
    for zone, subnet in azurerm_subnet.subnet_with_vm : zone => subnet.id
  }
  description = "Map of zone to subnet ID where VMs reside (replaces AWS public subnet concept)"
}

output "nat_subnet_id" {
  value = {
    for zone, subnet in azurerm_subnet.subnet_with_nat : zone => subnet.id
  }
  description = "Map of zone to subnet ID where NAT Gateway resides (replaces AWS private subnet concept)"
}

# Complete subnet resources - Maintained for backwards compatibility
# These outputs provide full subnet details including all properties
# Useful for security group associations and network planning
output "vm_subnet" {
  value       = azurerm_subnet.subnet_with_vm
  description = "The complete VM subnet resource (formerly public subnet in AWS)"
}

output "nat_subnet" {
  value       = azurerm_subnet.subnet_with_nat
  description = "The complete NAT subnet resource (formerly private subnet in AWS)"
}

# Note: We maintain this comprehensive output structure because:
# 1. Resource Groups: Azure's fundamental organization unit needs explicit outputs
# 2. Zone Mapping: Azure uses numeric zones (1,2,3) vs AWS's named zones (us-east-1a)
# 3. Subnet Evolution: Changed from public/private to vm/nat terminology while keeping functionality
# 4. Network Security: Azure's NSG model differs from AWS security groups
# 5. Future Compatibility: Structured to support potential multi-cloud deployments
# 
# We specifically avoided removing variables because:
# - It would break existing module references
# - Reduces flexibility for different environment configurations
# - Makes future cloud provider migrations more difficult
# - Removes important context for resource relationships
# - Limits ability to implement different security models per environment


terraform/modules/networking/variables.tf

variable "resource_group_name" {
  type        = string
  description = "Name of the resource group where networking resources will be created"
}

variable "location" {
  type        = string
  description = "Azure region where resources will be created"
}

variable "env" {
  type        = string
  description = "Environment name (dev, test, prod) for resource naming and tagging"
  default     = "test"
}

variable "prefix" {
  type        = string
  description = "Prefix to be used for resource naming"
  default     = "oii-test"
}

variable "redundancy" {
  type        = number
  description = "Number of availability zones to use (1-3). Controls the redundancy of resources"
  default     = 1
  validation {
    condition     = var.redundancy >= 1 && var.redundancy <= 3
    error_message = "Redundancy value must be between 1 and 3."
  }
}


terraform/secrets/secrets.tfvars.example

# Copy this file to secrets.tfvars and fill in your values
# Do not commit secrets.tfvars to version control

# Azure Authentication
subscription_id = "your-subscription-id"             # Example: "12345678-1234-1234-1234-123456789012"
tenant_id       = "your-tenant-id"                   # Example: "12345678-1234-1234-1234-123456789012"

# App Server Configuration
app_server_admin_username = "appadmin"               # Example: "appadmin"
app_server_ssh_key        = "your-ssh-public-key"    # SSH public key for app server access

# Storage Access Keys (Optional - can be generated by Azure)
backup_storage_access_key = "your-backup-storage-key"    # Will be auto-generated if not provided
app_data_storage_access_key = "your-app-data-key"        # Will be auto-generated if not provided

# Key Vault Access
key_vault_object_id = "your-key-vault-object-id"     # Example: "12345678-1234-1234-1234-123456789012"

# Email Service Configuration (if needed)
email_username = "your-email-username"               # Example: "service@yourdomain.com"
email_password = "your-email-password"               # Example: "your-secure-password"

# Jumpbox Access
jumpbox_admin_username = "jumpboxadmin"               
jumpbox_ssh_key        = "ssh-rsa AAAA..."           # Your public key here


terraform/templates/inventory.ini.tftpl

[jumpbox]
${jumpbox_public_ip} ansible_user=${jumpbox_admin_username}

[jumpbox:vars]
ansible_ssh_common_args='-o StrictHostKeyChecking=no'

[web]
${app_server_private_ip}

[workers]
%{ for worker_ip in worker_private_ips ~}
${worker_ip}
%{ endfor ~}

[web:vars]
ansible_ssh_private_key_file=~/.ssh/oii-internal-key-rsa
ansible_ssh_common_args='-o StrictHostKeyChecking=no -o ProxyCommand="ssh ${jumpbox_admin_username}@${jumpbox_public_ip} -i ~/.ssh/oii-internal-key-rsa -W %h:%p"'
ansible_user=${app_server_admin_username}

[workers:vars]
ansible_ssh_private_key_file=~/.ssh/oii-internal-key-rsa
ansible_ssh_common_args='-o StrictHostKeyChecking=no -o ProxyCommand="ssh ${jumpbox_admin_username}@${jumpbox_public_ip} -i ~/.ssh/oii-internal-key-rsa -W %h:%p"'
ansible_user=${app_server_admin_username} 


terraform/userdata/appserver-init.sh

# Update system
dnf update -y

# Install required utilities
dnf install -y \
    inotify-tools \
    ansible \
    xfsprogs
# Wait for data disk to be available
while [ ! -b /dev/sdc ]; do
    echo "Waiting for data disk to be attached..."
    sleep 1
done

# Create PostgreSQL data directory
mkdir -p /var/lib/pgsql

# Format the data disk (in Azure, typically /dev/sdc)
mkfs.xfs /dev/sdc

# Add entry to fstab for automatic mounting after reboot
echo "/dev/sdc /var/lib/pgsql xfs defaults 0 0" >> /etc/fstab

# Mount all filesystems
mount -a

# Create .ssh directory if it doesn't exist
mkdir -p /home/${app_server_admin_username}/.ssh

# Set correct permissions and ownership
chmod 700 /home/${app_server_admin_username}/.ssh
chown -R ${app_server_admin_username}:${app_server_admin_username} /home/${app_server_admin_username}/.ssh


terraform/userdata/jumpbox-init.sh.tftpl

# Update system packages
dnf update -y

# Install required packages
dnf install -y inotify-tools
dnf install -y ansible
dnf install -y xfsprogs  # Added for XFS support

# Create .ssh directory if it doesn't exist
mkdir -p /home/${jumpbox_admin_username}/.ssh

# Write SSH private key
echo "${key_mat}" > /home/${jumpbox_admin_username}/.ssh/id_rsa

# Set correct permissions and ownership
chmod 600 /home/${jumpbox_admin_username}/.ssh/id_rsa
chown -R ${jumpbox_admin_username}:${jumpbox_admin_username} /home/${jumpbox_admin_username}/.ssh